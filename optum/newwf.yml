name: Upload Test Case Files to ADLS

on:
  workflow_dispatch:  # You can also trigger on push/PR as needed

jobs:
  upload_files:
    runs-on: ubuntu-latest

    env:
      ENV: dev  # Change this to qa/stage/prod as needed

    steps:
      - name: ğŸ“¦ Checkout Repository
        uses: actions/checkout@v3

      - name: ğŸ› ï¸ Install Dependencies (jq)
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: ğŸ” Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: ğŸš€ Upload Test Case Files to ADLS
        env:
          ACCOUNT_NAME: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
          CONTAINER_NAME: ${{ secrets.AZURE_STORAGE_CONTAINER }}
        run: |
          CONFIG_FILE="config/test_config.json"
          echo "ğŸ“„ Reading config from $CONFIG_FILE"

          jq -c '.test_cases[] | select(.IsActive=="true")' "$CONFIG_FILE" | while read tc; do
            id=$(echo "$tc" | jq -r '.ID')
            feed_name=$(echo "$tc" | jq -r '.Feed_Name')
            tc_dir="regression/test_cases/tc${id}"

            echo ""
            echo "=============================="
            echo "âš™ï¸  Test Case ID: $id"
            echo "ğŸ“¦ Feed Name: $feed_name"
            echo "ğŸ“ Local Folder: $tc_dir"
            echo "=============================="

            # Upload input_files
            if [ -d "$tc_dir/input_files" ]; then
              echo "ğŸ“‚ Found input_files folder for TC$id"
              find "$tc_dir/input_files" -type f | while read file; do
                filename=$(basename "$file")
                destination_blob="data/$ENV/bronze/${feed_name}/tarnishedbronze/landed_feed_files/${filename}"

                echo "ğŸšš Uploading input file:"
                echo "   ğŸ”¹ Source     : $file"
                echo "   ğŸ”¸ Destination: $destination_blob"

                az storage blob upload \
                  --account-name "$ACCOUNT_NAME" \
                  --container-name "$CONTAINER_NAME" \
                  --file "$file" \
                  --name "$destination_blob" \
                  --overwrite \
                  --auth-mode login
              done
            else
              echo "âš ï¸  No input_files folder found for TC$id"
            fi

            # Upload sql_files
            if [ -d "$tc_dir/sql_files" ]; then
              echo "ğŸ“‚ Found sql_files folder for TC$id"
              find "$tc_dir/sql_files" -type f | while read file; do
                filename=$(basename "$file")
                destination_blob="data/$ENV/bronze/${feed_name}/tarnishedbronze/landed_feed_files/sql_files/${filename}"

                echo "ğŸšš Uploading SQL file:"
                echo "   ğŸ”¹ Source     : $file"
                echo "   ğŸ”¸ Destination: $destination_blob"

                az storage blob upload \
                  --account-name "$ACCOUNT_NAME" \
                  --container-name "$CONTAINER_NAME" \
                  --file "$file" \
                  --name "$destination_blob" \
                  --overwrite \
                  --auth-mode login
              done
            else
              echo "âš ï¸  No sql_files folder found for TC$id"
            fi

            echo "âœ… Finished uploading for Test Case ID: $id"
            echo ""
          done
